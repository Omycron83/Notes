Transformers are a [[Neural Network]] variant mainly utilizing attention, encoding and embedding as well as context memory to better pattern recognition when dealing with sequential or high dimensional data by selectively focusing on information. 

It was originally introduced in the paper 
# Attention:



*Source:* https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/