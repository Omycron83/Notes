# LinA I

## Grundlagen der linearen Algebra:
1. Lineare Gleichungssysteme  
1.1. Der reelle _n_-dimensionale Raum  
1.2. Geraden in der Ebene
1.3. Geraden und Ebenen im ℝ3
1.4. Das Eliminationsverfahren von Gauss
1.4.1-1.4.2. Lineare Gleichungssysteme, Matrixschreibweise, Lösungsmenge
1.4.3-1.4.4. Lösen eines Gleichungssystems in Zeilenstufenform
1.4.5. Spezialfall: quadradische Matrix _r=n_
1.4.6. Elementare Zeilenumformungen
1.4.7. Jede Matrix kann durch elementare Zeilenumformungen in Zeilenstufenform gebracht werden

## Algebraische Grundlagen:

### 2.1 Mengen, Relationen und Abbildungen
2.1.1. Mengen
2.1.2. Teilmenge, Vereinigung, Durchschnitt, Differenzmenge
2.1.3. Abbildungen
2.1.4. injektiv, surjektiv, bijektiv
2.1.5. Komposition von Abbildungen
2.1.6. Direktes Produkt von Mengen
2.1.7. Graph einer Funktion
2.1.8. Relationen, Äquivalenzrelationen
### 2.2. Gruppen
2.2.1. Verknüpfungen
2.2.2. Gruppen: Definition & Beispiele
2.2.3. Erste Folgerungen aus den Gruppenaxiomen
2.2.4. Alternatives zweites Gruppenaxiom
2.2.5. Verknüpfungstafeln für die Grupen bis Ordnung 4
2.2.6. Untergruppen und Homomorphismen
2.2.7.-2.2.8. Die zyklischen Gruppen ℤ/_m_ℤ
### 2.3. Ringe, Körper, 
2.3.1. Ringe
2.3.2. Nullteilerfreiheit
2.3.3. Körper\
2.3.4. Beispiele für Körper: ℚ, ℝ, ℂ, 𝔽p = ℤ/pℤ'
### 2.3.5 Polynome
2.3.5. Polynome über einem Körper
2.3.6. Der Polynomring K[t]
2.3.7. Division mit Rest
2.3.8. Integritätsringe, Einheiten, Teilbarkeit
2.3.8. Größter gemeinsamer Teiler, euklidischer Algorithmus
2.3.9. Relation von Bézout, erweiterter euklidischer Algorithmus
2.3.10. Nullstellen von Polynomen und Teilbarkeit durch Linearfaktoren
2.3.10. Vielfachheit einer Nullstelle
2.3.11. Fundamentalsatz der Algebra
2.3.12. Nullstellen und Faktorisierung von reellen Polynomen
2.3.13. Elementarsymmetrische Funktionen
\
## Grundlagen der Linearen Algebra:
### 2.4. Vektorräume
2.4.1. Vektorraumaxiome und einfache Folgerungen, Beispiele
2.4.2. Untervektorräume. Definition und Beispiele
2.4.3. Untervektorräume sind Vektorräume, Schnitte
2.4.4. Linearkombinationen und erzeugte Unterräume
2.4.5. Lineare Unabhängigkeit (Definition und Lemma)
2.4.5. Lineare Unabhängigkeit (Beispiele und Bemerkung)
### 2.5. Basis und Dimension
2.5.1. Erzeugendensystem und Basis: Definitionen und Beispiele
2.5.2. Äquivalente Charakterisierungen von Basen
2.5.3. Basisauswahlsatz
2.5.4. Austauschsatz
2.5.5. Dimension, Basisergänzungssatz, Beispiele
2.5.6. Für Moduln (das sind "Vektorräume" über Ringen) kann man den Begriff der Dimension so nicht definieren
2.5.7. Mit dem Gauß-Algorithmus ein Erzeugendensystem zu einer Basis machen
### 2.6. Summen von Vektorräumen
2.6.1. Definition und Dimensionsformel für Summen
2.6.2. Direkte Summe von zwei Unterräumen
2.6.3. Mehr über direkte Summen von zwei Unterräumen
2.6.4. Direkte Summen von mehreren Unterräumen
### 3. Lineare Abbildungen
3.1.2. Lineare Abbildungen: Definition
3.1.2. Isomorphismus, Endomorphismus, Automorphismus. Einfache Folgerungen
3.1.3. Vektorraum Hom(_V,W_) der linearen Abbildungen und Endomorphismenring End(_V_)
3.2. Bild, Fasern und Kern, Quotientenvektorräume
3.2.1. Definition _Bild, Faser, Kern_. Injektivität und surjektivität
3.2.4. Dimensionsformel: dim _V_ = dim Ker _F_ + dim Im _F_, Beweis und Folgerungen
3.2.5. Faktorisierungssatz
3.2.2. Bild und Faser
3.2.3. Affine Unterräume (Definition)
3.2.6.-3.2.9 Quotientenvektorräume (im Vergleich zum Buch gestrafft und mit anderen Beispielen)

## Einbettung von Matrizen:
### 3.3. Lineare Gleichungssysteme und der Rang einer Matrix
3.3.1. Der Lösungsraum des homogenen/inhomogenen Systems ist ein Untervektorraum/affiner Unterraum
3.3.2. Rangsatz: Spaltenrang = Zeilenrang
3.3.3. Zusammenfassung: Lineare Abbildungen und lineare Gleichungssysteme
3.3.4. Rangbedingungen für eindeutige und universelle Lösbarkeit eines Gleichungssystems
3.5. Mulitplikation von Matrizen
3.5.1. Verkettung von linearen Abbildungen und Matrixmultiplikation 
3.5.2. Rechenschema, Beispiele
3.5.3. Noch zwei Spezialfälle: 2×2-Drehmatrizen, Matrix mal Spaltenvektor
3.5.4. Rechenregeln für Matrizenmultiplikation
3.5.6. Invertierbare Matrizen und allgemeine lineare Gruppe GL(_n_,_K_)
Inversion einer Matrix
![[Inversion_einer_Matrix.pdf]]
Modifizierter Gauß-Algorithmus
![[Modifizierter_Gauss.pdf]]
3.7. Elementarmatrizen und Matrizenumformungen (nur kurz erklärt)
### 3.4. Lineare Abbildungen und Matrizen
3.4.1. Die Werte auf einer Basis bestimmen eine lineare Abbildung
![[LinA_I_Vorlesung_28_extra.pdf]]
3.4.2. Weitere Folgerungen. Wahl von Basen bestimmt Koordinatensysteme und erlaubt die Darstellung einer linearen Abbildung durch eine Matrix
3.6.3. Kordinatensysteme ΦA:Kn→Vund darstellende Matrizen MAB(F)
3.6.4. Komposition von linearen Abbildungen entspricht Multiplikation der darstellenden Matrizen
3.4.3. Die darstellende Matrix einer linearen Abbildung wird für speziell angepasste Basen ganz einfach
3.4.4. Für einen Endomorphismus ist es sinnvoll, für Urbild und  Bild dieselbe Basis zu verwenden. Die analoge Frage, wie man diese _eine_ Basis so wählen kann, damit die darstellende Matrix möglichst einfach wird, ist viel schwieriger zu beantworten. (Die Antwort liefert der Satz von der Jordanschen Normalform, den wir im 2. Semester behandeln werden.)
3.6.1. Die Transformationsmatrix des Basiswechsels SAB
3.6.2. Die Transformationsmatrix der Koordinaten TAB=(SAB)−1=SBA mit Beispielen
3.6.5. Transformationsformel für darstellende Matrizen: MA′B′(F)=TBB′MAB(F)(TAA′)−1
3.6.6. (Fortsetzung) Beispiel zur Transformationsformel
3.6.7. Äquivalente und Ähnliche Matrizen

# LinA II
## Determinanten:
### 4.1 Beispiele und Definitionen
4.1.1 Anschaulich-geometrische Behandlung
![[Det_geometrisch.pdf]]
4.1.2 Definition der Determinante durch charakteristische Eigenschaften (D1)-(D2)  
4.1.3 Erste Folgerungen [nur (D4)-(D7), (D13). Die anderen später mit Leibniz-Formel]
### 4.2 Permutationen
4.2.1 Permutationen und die symmetrischen Gruppen Sn
4.2.2 Transpositionen
4.2.3 Fehlstände und Signum
4.2.4 Die Alternierende Gruppe An
### 4.2 Fortfuehrung Determinanten
4.2.5 Die Leibniz-Formel
4.2.5 Die Leibniz-Formel, Fortsetzung: Existenz und Eindeutigkeit der Determinante
Determinante einer oberen Dreiecksmatrix [Eigenschaft (D8) in 4.1.3]
Determinante einer Blockmatrix der Gestalt (A1C0A2) [Eigenschaft (D9) in 4.1.3]
A ist invertierbar ⇔detA≠0 [Eigenschaft (D10) in 4.1.3]
Determinantenmultiplikationssatz [Eigenschaft (D11) in 4.1.3]
detA=detAt [Eigenschaft (D12) in 4.1.3]
Cramersche Regel [4.3.4 im Buch]  
Entwicklungssatz von Laplace [4.3.2 im Buch]
- Entwicklungssatz von Laplace (Fortsetzung)
Berechnung der Determinante mit dem Gauß-Algorithmus
### 4.4 Determinante eines Endomorphismus und Orientierung
4.4.1 Determinante eines Endomorphismus
4.4.2 Orientierungstreue und orientierungsumkehrende Endomorphismen  
4.4.3 Orientierung eines reellen Vektorraums als Äquivalenzklasse von Basen
4.4.4 Die zwei Orientierungen eines reellen Vektorraums sind genau die Zusammenhangskomponenten des Raums der Basen. Für Rn entsprechen sie den zwei Zusammenhangskomponenten von GL(n,R). (Ohne Beweis, nur ungefähre Idee)
## 5. 1 Eigenwerte und Normalformen
5.1 Beispiele und Definitionen
5.1.1 Eigenwerte und Eigenvektoren
5.1.2 Diagonalisierbarkeit
5.1.3 Eigenvektoren zu verschiedenen Eigenwerten sind linear unabhängig
5.1.4 Der Eigenraum Eig(F,λ) eines Endomorphismus F zu einer Zahl λ
5.2 Das charakteristische Polynom
5.2.1-3 Charakteristische Funktion und charakteristisches Polynom
5.2.4 Berechnung der Eigenräume und Beispiele
### 5.3 Diagonalisierung
5.3.1 Eine notwendige und eine hinreichende Bedingung für Diagonalisierbarkeit
5.3.4 Beispiel aus dem Buch und zusätzlich A=(λ10λ)  
5.3.2 Algebraische und geometrische Vielfachheit eines Eigenwerts
5.3.3 Notwendige und hinreichende Bedingungen für Diagonalisierbarkeit
Extra: Potenzen einer diagonalisierbaren Matrix, die Pell-Folge
5.3.5 Beispiel einer linearen Differentialgleichung: die gedämpfte Schwingung
5.3.6 Zwei diagonalisierbare Endomorphismen sind genau dann simultan diagonalisierbar, wenn sie kommutieren.  
### 5.5 Die Jordansche Normalform. Formulierung des Satzes und Anwendungen
5.5.1 Jordan-Blöcke, Jordan-Matrizen, Satz von der Jordanschen Normalform
5.5.2 An der Jordanschen Normalform kann man die algebraischen und geometrischen Vielfachheiten der Eigenwerte ablesen
5.5.3 Satz von der Jordanschen Normalform (Matrixversion)
5.5.5 Satz von der Jordanschen Normalform (Jordan-Ketten-Version)
5.5.3 Anwendung: Lineare Diffenrentialgleichungen  
### 5.6 Polynome von Endomorphismen
5.6.1 Spezialfall des Satzes von Cayley-Hamilton für diagonalisierbare Endomorphismen
5.6.2 Einsetzungshomomorphismen
5.6.3 Kerp(F) ist ein F-invarianter Unterraum
5.6.4 Für F∈End(V) gibt es ein Polynom mit p(F)=0 und −∞<degp<(dimV)2. Beispiele.
5.6.5 Das Ideal eines Endomorphismus oder einer Matrix _(wird fortgesetzt)_
5.6.5 Das Ideal eines Endomorphismus oder einer Matrix _(Fortsetzung)_
5.6.6 An der Jordanschen Normalform kann man das Minimalpolynom ablesen.
5.6.7 Der Satz von Cayley-Hamilton
### 5.7 Die Jordansche Normalform, Beweis  
5.7.2 Hauptraumzerlegung (Satz und Lemma mit Beweis)
5.7.2 _Fortsetzung_ (Korollar zum Lemma und Beweis des Satzes)
5.7.1 Normalform eines nilpotenten Endomorphismus
5.7.3 Beweis des Satzes von der Jordanschen Normalform. Bemerkung über abgeschwächte Voraussetzungen und die reelle Jordanschen Normalform (s. Aufgabe 12)
## Innere Produkte:
### 6.1 Kanonische Skalar- und Vektorprodukte
6.1 Das kanonische Skalarprodukt im Rn
6.1.1 Skalarprodukt, Eigenschaften, [Euklidische] Norm und Metrik  
6.1.2 Eigenschaften von Norm und Metrik  
6.1.3 Ungleichung von Cauchy-Schwarz
6.1.4 Winkelmessung
6.2 Das Vektorprodukt im R3
6.2.1 Definition und Eigenschaften  
6.2.2 ⟨x×y,z⟩=det(xyz) und ∥x×y∥2=∥x∥2∥y∥2−⟨x,y⟩2
6.3 Das kanonische Scalarprodukt im Cn
6.3.1 Definition und Eigenschaften  
6.3.2 Skalarprodukt im Cn vs Scalarprodukt im R2n
### 6.4 Bilinearformen ~~und quadratische Formen~~  
6.4.1 Bilinearform, symmetrisch, alternierend, schiefsymmetrisch  
6.4.2 Matrix einer Bilinearform
### 6.5 Skalarprodukte
6.5.1 Sesquilinearformen, hermitesch, darstellende Matrix bzgl. einer Basis
6.5.2 positiv definit
6.5.3 Cauchy-Schwarzsche Ungleichung, induzierte Norm und Metrik
6.5.4 orthogonale Vektoren und Unterräume, Orthonomormalbasen und ihre Koordinatenabbildungen
6.5.5 Der Orthonormalisierungssatz (benannt nach [Jørgen Gram](https://de.wikipedia.org/wiki/J%C3%B8rgen_Pedersen_Gram) und [Erhard Schmidt](https://de.wikipedia.org/wiki/Erhard_Schmidt_(Mathematiker)))
### 6.6 Orthogonale und unitäre Endomorphismen
6.6.1 Definition und erste Folgerungen
Extra: Die Isometrien eines euklidischen Vektorraums [[Notizen](https://isis.tu-berlin.de/pluginfile.php/3252286/mod_label/intro/Isometrien.pdf)]  
6.6.2 Orthogonale und unitäre Matrizen und die Gruppen O(n), SO(n), U(n) und SU(n) _(wird fortgesetzt)_
6.6.2 Spalten einer orthogonalen/unitären Matrix bilden eine Orthonormalbasis. Zeilen ebenso.
6.6.3 O(2) und O(3)
6.7 Selbstadjungierte und normale Endomorphismen
6.7.1 Selbstadjungierte Endomorphismen und ihre Matrixdarstellungen bzgl. einer Orthonormalbasis
6.7.2 Diagonalisierungssatz _(Fortsetzung folgt)_  
6.7.2 Diagonalisierungssatz _(Beweis)_
Normal Endormorphismen und normale Matrizen
Diagonalisierungssatz für normale Endomorphismen
