In machine learning, overfitting refers to a model discovering patterns inherent in the provided population sample, i.e. the training set, that are however not inherent in the population. This is a manifestation of a model having high variance. Techniques to decrease overfitting and high variance are known as regularization techniques and are often inherent to specific models. 

The opposite, i.e. the manifestation of high bias, is conversely known as underfitting. However, this doesn't have the opposite interpretation using pattern recognition.

A visualization of overfitting vs. underfitting vs. an optimal model with balanced bias and variance:
![[Pasted image 20230822153228.png]]
